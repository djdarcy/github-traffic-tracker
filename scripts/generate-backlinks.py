#!/usr/bin/env python3
"""Generate a backlinks index for an Obsidian-style knowledge vault.

Scans all .md files in a vault directory, parses [[wikilinks]] and
[[wikilinks|aliases]], builds a reverse-link (backlinks) index, and
writes it to _oracle/backlinks.md.

Zero dependencies beyond Python stdlib. Optional networkx integration
for graph export (--graph flag).

Usage:
    python generate-backlinks.py                        # Auto-detect vault from cwd
    python generate-backlinks.py /path/to/vault         # Explicit vault path
    python generate-backlinks.py --json                 # JSON output to stdout
    python generate-backlinks.py --orphans              # List isolated notes
    python generate-backlinks.py --broken               # List broken wikilinks
    python generate-backlinks.py --stats                # Summary statistics
    python generate-backlinks.py --graph out.json       # NetworkX graph export (requires networkx)
    python generate-backlinks.py --dry-run              # Preview without writing
"""

import argparse
import json
import re
import sys
from pathlib import Path

# ---------------------------------------------------------------------------
# Wikilink regex: matches [[target]] and [[target|alias]]
# Does NOT match ![[embeds]] (those start with !)
# ---------------------------------------------------------------------------
WIKILINK_RE = re.compile(r'(?<!!)\[\[([^\]|]+?)(?:\|[^\]]+?)?\]\]')

# Fenced code block delimiters (``` or ~~~, with optional language tag)
FENCE_RE = re.compile(r'^(`{3,}|~{3,})')


def find_vault_root(start: Path) -> Path | None:
    """Walk upward from start looking for private/claude/ or _maps/."""
    current = start.resolve()
    # If we're already in or pointing at the vault
    if (current / '_maps').is_dir():
        return current
    if (current / 'private' / 'claude').is_dir():
        return current / 'private' / 'claude'
    # Walk up
    for parent in current.parents:
        candidate = parent / 'private' / 'claude'
        if candidate.is_dir():
            return candidate
    return None


INLINE_CODE_RE = re.compile(r'`[^`]+`')


def parse_wikilinks(text: str) -> list[str]:
    """Extract wikilink targets from markdown text, skipping fenced and inline code."""
    targets = []
    in_fence = False
    fence_marker = ''

    for line in text.splitlines():
        fence_match = FENCE_RE.match(line.strip())
        if fence_match:
            marker = fence_match.group(1)
            if not in_fence:
                in_fence = True
                fence_marker = marker[0]  # ` or ~
            elif line.strip().startswith(fence_marker):
                in_fence = False
                fence_marker = ''
            continue

        if in_fence:
            continue

        # Strip inline code spans before searching for wikilinks
        cleaned = INLINE_CODE_RE.sub('', line)

        for match in WIKILINK_RE.finditer(cleaned):
            targets.append(match.group(1).strip())

    return targets


def build_indices(vault_root: Path) -> tuple[dict, dict, dict]:
    """Build forward links, backlinks, and file index for the vault.

    Returns:
        (forward_links, backlinks, file_index)
        - forward_links: {stem: [target_stems]}
        - backlinks: {stem: [source_stems]}
        - file_index: {stem: Path}
    """
    file_index: dict[str, Path] = {}
    for f in sorted(vault_root.rglob('*.md')):
        file_index[f.stem] = f

    forward: dict[str, list[str]] = {}
    for stem, fpath in file_index.items():
        text = fpath.read_text(encoding='utf-8', errors='ignore')
        links = parse_wikilinks(text)
        forward[stem] = links

    backlinks: dict[str, list[str]] = {stem: [] for stem in file_index}
    for source, targets in forward.items():
        seen = set()
        for target in targets:
            if target in backlinks and target not in seen:
                backlinks[target].append(source)
                seen.add(target)

    return forward, backlinks, file_index


def format_backlinks_md(backlinks: dict, file_index: dict) -> str:
    """Format the backlinks index as markdown for _oracle/backlinks.md."""
    lines = [
        '---',
        'type: oracle-metadata',
        'purpose: Reverse-link index -- which documents reference each document',
        f'generated-by: scripts/generate-backlinks.py',
        '---',
        '',
        '# Backlinks Index',
        '',
        'Auto-generated reverse-link index. For each document, lists all documents that',
        'reference it via `[[wikilinks]]`. Regenerate with:',
        '',
        '```bash',
        'python scripts/generate-backlinks.py',
        '```',
        '',
    ]

    # Sort by backlink count (most referenced first), then alphabetically
    sorted_notes = sorted(
        backlinks.items(),
        key=lambda x: (-len(x[1]), x[0])
    )

    # Stats header
    with_bl = sum(1 for v in backlinks.values() if v)
    total_entries = sum(len(v) for v in backlinks.values())
    lines.append(f'**{with_bl}** notes with backlinks, **{total_entries}** total references')
    lines.append('')

    # Only show notes that have backlinks
    for note, sources in sorted_notes:
        if not sources:
            continue
        lines.append(f'## {note}')
        lines.append('')
        for src in sorted(sources):
            lines.append(f'- `{src}`')
        lines.append('')

    return '\n'.join(lines)


def get_orphans(forward: dict, backlinks: dict) -> list[str]:
    """Find notes with no inbound or outbound wikilinks."""
    orphans = []
    for stem in sorted(forward.keys()):
        has_outbound = bool(forward.get(stem))
        has_inbound = bool(backlinks.get(stem))
        if not has_outbound and not has_inbound:
            orphans.append(stem)
    return orphans


def get_broken_links(forward: dict, file_index: dict) -> dict[str, list[str]]:
    """Find wikilinks that point to non-existent notes."""
    existing = set(file_index.keys())
    broken: dict[str, list[str]] = {}
    for source, targets in forward.items():
        for target in targets:
            if target not in existing:
                broken.setdefault(source, []).append(target)
    return broken


def validate_against_obsidiantools(vault_root: Path, our_backlinks: dict):
    """Cross-validate our backlinks against obsidiantools for redundancy."""
    try:
        import obsidiantools.api as otools
    except ImportError:
        print('Error: obsidiantools is required for --validate. '
              'Install with: pip install obsidiantools', file=sys.stderr)
        sys.exit(1)

    print('Running obsidiantools for cross-validation...')
    vault = otools.Vault(vault_root).connect()
    ot_backlinks = vault.backlinks_index

    # Normalize both to sets for comparison
    our_set: dict[str, set[str]] = {
        k: set(v) for k, v in our_backlinks.items() if v
    }
    ot_set: dict[str, set[str]] = {
        k: set(v) for k, v in ot_backlinks.items() if v
    }

    all_notes = sorted(set(our_set.keys()) | set(ot_set.keys()))

    only_ours = 0
    only_theirs = 0
    agree = 0

    for note in all_notes:
        ours = our_set.get(note, set())
        theirs = ot_set.get(note, set())
        diff_ours = ours - theirs
        diff_theirs = theirs - ours
        common = ours & theirs
        agree += len(common)

        if diff_ours:
            only_ours += len(diff_ours)
            for src in sorted(diff_ours):
                print(f'  [regex only]  {src} -> {note}')
        if diff_theirs:
            only_theirs += len(diff_theirs)
            for src in sorted(diff_theirs):
                print(f'  [obstools only]  {src} -> {note}')

    total_ours = sum(len(v) for v in our_set.values())
    total_theirs = sum(len(v) for v in ot_set.values())
    print(f'\nValidation summary:')
    print(f'  Regex parser:      {total_ours} backlink edges')
    print(f'  obsidiantools:     {total_theirs} backlink edges')
    print(f'  Agree:             {agree}')
    print(f'  Regex-only:        {only_ours} (typically YAML frontmatter wikilinks)')
    print(f'  obsidiantools-only: {only_theirs}')


def export_graph(forward: dict, output_path: str):
    """Export the link graph as JSON using networkx (optional dependency)."""
    try:
        import networkx as nx
    except ImportError:
        print('Error: networkx is required for --graph. Install with: pip install networkx',
              file=sys.stderr)
        sys.exit(1)

    G = nx.DiGraph()
    for source, targets in forward.items():
        G.add_node(source)
        for target in targets:
            G.add_edge(source, target)

    data = nx.node_link_data(G, edges='links')
    with open(output_path, 'w', encoding='utf-8') as f:
        json.dump(data, f, indent=2)
    print(f'Graph exported: {len(G.nodes)} nodes, {len(G.edges)} edges -> {output_path}')


def main():
    parser = argparse.ArgumentParser(
        description='Generate backlinks index for an Obsidian-style knowledge vault.'
    )
    parser.add_argument('vault_path', nargs='?', default='.',
                        help='Path to vault root (default: auto-detect from cwd)')
    parser.add_argument('--json', action='store_true',
                        help='Output backlinks as JSON to stdout')
    parser.add_argument('--orphans', action='store_true',
                        help='List isolated notes (no links in or out)')
    parser.add_argument('--broken', action='store_true',
                        help='List broken wikilinks (target does not exist)')
    parser.add_argument('--stats', action='store_true',
                        help='Print summary statistics')
    parser.add_argument('--graph', metavar='FILE',
                        help='Export link graph as JSON (requires networkx)')
    parser.add_argument('--dry-run', action='store_true',
                        help='Preview output without writing _oracle/backlinks.md')
    parser.add_argument('--output', metavar='FILE',
                        help='Write backlinks to a custom path instead of _oracle/backlinks.md')
    parser.add_argument('--validate', action='store_true',
                        help='Cross-validate against obsidiantools (requires pip install obsidiantools)')

    args = parser.parse_args()

    # Find vault root
    start = Path(args.vault_path).resolve()
    vault_root = find_vault_root(start)
    if vault_root is None:
        # Fall back to the given path directly
        vault_root = start
        if not any(vault_root.rglob('*.md')):
            print(f'Error: No .md files found in {vault_root}', file=sys.stderr)
            sys.exit(1)

    # Build indices
    forward, backlinks, file_index = build_indices(vault_root)

    # Cross-validation mode
    if args.validate:
        validate_against_obsidiantools(vault_root, backlinks)
        return

    # Handle action flags
    if args.json:
        # Output backlinks as JSON
        output = {
            note: sorted(set(sources))
            for note, sources in backlinks.items()
            if sources
        }
        json.dump(output, sys.stdout, indent=2)
        print()
        return

    if args.orphans:
        orphans = get_orphans(forward, backlinks)
        print(f'Isolated notes ({len(orphans)}):')
        for o in orphans:
            print(f'  - {o}')
        return

    if args.broken:
        broken = get_broken_links(forward, file_index)
        if not broken:
            print('No broken wikilinks found.')
        else:
            total = sum(len(v) for v in broken.values())
            print(f'Broken wikilinks ({total}):')
            for source, targets in sorted(broken.items()):
                for t in targets:
                    print(f'  {source} -> [[{t}]] (not found)')
        return

    if args.graph:
        export_graph(forward, args.graph)
        return

    if args.stats:
        with_bl = sum(1 for v in backlinks.values() if v)
        total_bl = sum(len(v) for v in backlinks.values())
        total_fl = sum(len(v) for v in forward.values())
        orphans = get_orphans(forward, backlinks)
        broken = get_broken_links(forward, file_index)
        broken_count = sum(len(v) for v in broken.values())

        print(f'Vault: {vault_root}')
        print(f'Total .md files: {len(file_index)}')
        print(f'Forward link edges: {total_fl}')
        print(f'Notes with backlinks: {with_bl}')
        print(f'Total backlink edges: {total_bl}')
        print(f'Isolated notes: {len(orphans)}')
        print(f'Broken wikilinks: {broken_count}')

        # Top referenced
        sorted_bl = sorted(backlinks.items(), key=lambda x: -len(x[1]))[:5]
        print('\nTop 5 most referenced:')
        for name, sources in sorted_bl:
            print(f'  {len(sources):3d} <- {name}')
        return

    # Default: generate _oracle/backlinks.md
    md_content = format_backlinks_md(backlinks, file_index)

    if args.dry_run:
        print(md_content)
        return

    # Determine output path
    if args.output:
        out_path = Path(args.output)
    else:
        oracle_dir = vault_root / '_oracle'
        oracle_dir.mkdir(exist_ok=True)
        out_path = oracle_dir / 'backlinks.md'

    out_path.write_text(md_content, encoding='utf-8')

    # Print summary
    with_bl = sum(1 for v in backlinks.values() if v)
    total_bl = sum(len(v) for v in backlinks.values())
    print(f'Wrote {out_path}')
    print(f'  {len(file_index)} files scanned, {with_bl} notes with backlinks, {total_bl} link edges')


if __name__ == '__main__':
    main()
